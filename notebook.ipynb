{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import numpy as jnp, jit, vmap, random\n",
    "from jaxmarl import make\n",
    "import matplotlib.animation as animation\n",
    "from jaxmarl.environments.smax import map_name_to_scenario, SMAX\n",
    "from jaxmarl.environments.smax.smax_env import State as SMAXState  # use to unstack state carry from lax scan\n",
    "from jaxmarl.environments.smax.heuristic_enemy import HeuristicPolicyState as EnemyState\n",
    "from jaxmarl.environments.smax.heuristic_enemy_smax_env import State as State\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from functional import partial\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "import esch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vtraj(config):  # returns a function that runs n_envs environments in parallel. Current actions are random.\n",
    "    env = make(config['env'], **config['env_config'])\n",
    "    config['n_agents'] = env.num_agents * config['n_envs']\n",
    "\n",
    "    def init_runner_state(key):\n",
    "        key, key_reset = random.split(key)\n",
    "        key_reset      = random.split(key_reset, config['n_envs'])\n",
    "        obsv, state    = vmap(env.reset)(key_reset)\n",
    "        return (state, obsv, key)\n",
    "\n",
    "    def env_step(runner_state, seqs):\n",
    "        env_state, last_obs, key = runner_state   # random key for sampling actions\n",
    "        key, key_act             = random.split(key)\n",
    "\n",
    "        key_act = random.split(key_act, config['n_agents']).reshape((env.num_agents, config['n_envs'], -1))\n",
    "        # this is the line we wanna inject the action into from.\n",
    "        actions = {agent: jnp.ones_like(vmap(env.action_space(agent).sample)(key_act[i])) + 1 for i, agent in enumerate(env.agents)}\n",
    "\n",
    "        key, key_step = random.split(key)\n",
    "        key_step      = random.split(key_step, config['n_envs'])\n",
    "\n",
    "        obsv, env_state, reward, done, infos = vmap(env.step)(key_step, env_state, actions)\n",
    "        return (env_state, obsv, key), (key_step, env_state, actions)  # reward)\n",
    "\n",
    "\n",
    "\n",
    "    def vtraj_fn(key):\n",
    "        key, key_init       = random.split(key)\n",
    "        runner_state        = init_runner_state(key_init)\n",
    "        # scan :: (c -> a -> (c, b)) -> c -> [a] -> (c, [b])\n",
    "        runner_state, hist = jax.lax.scan(env_step, runner_state, None, length=config['max_steps'])\n",
    "        return runner_state, hist\n",
    "\n",
    "    return vtraj_fn, env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config     = {\"num_allies\": 40,  'num_enemies': 40}\n",
    "config         = {\"max_steps\": 30, \"n_envs\": 6, \"env\": \"SMAX\", \"env_config\": env_config}\n",
    "vtraj_fn, env  = make_vtraj(config)\n",
    "vtraj          = jit(vtraj_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng, key                = random.split(random.PRNGKey(0))\n",
    "(state, obs, key), hist = vtraj(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_state_seq_fn(env, hist):\n",
    "    xs = []\n",
    "    for i in range(config['max_steps']):\n",
    "        state = SMAXState(\n",
    "            unit_positions=hist[1].unit_positions[i, :],\n",
    "            unit_types=hist[1].unit_types[i, :],\n",
    "            unit_teams=hist[1].unit_teams[i, :],\n",
    "            unit_health=hist[1].unit_health[i, :],\n",
    "            unit_weapon_cooldowns=hist[1].unit_weapon_cooldowns[i, :],\n",
    "            prev_actions=hist[1].prev_actions[i, :],\n",
    "            time=hist[1].time[i],\n",
    "            terminal=hist[1].terminal[i],\n",
    "            unit_alive=hist[1].unit_alive[i, :]\n",
    "        )\n",
    "        action = {\n",
    "            ally: actions[i] for ally, actions in hist[2].items()\n",
    "        }\n",
    "        xs.append((hist[0][i], state, action))\n",
    "    return vmap(env.expand_state_seq)(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {'agent': 'random', 'scenario': f'{env_config[\"num_allies\"]}v{env_config[\"num_enemies\"]}'}                                                      \n",
    "seqs = expand_state_seq_fn(env, hist)\n",
    "esch.worlds_fn(seqs, info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
