{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import numpy as jnp, jit, vmap, random\n",
    "import chex\n",
    "from jaxmarl import make\n",
    "from jaxmarl.environments.smax import map_name_to_scenario\n",
    "from einops import rearrange\n",
    "from functional import partial\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import darkdetect, imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "rcParams[\"font.family\"] = \"monospace\"\n",
    "rcParams[\"font.monospace\"] = \"Fira Code\"\n",
    "bg = \"black\" if darkdetect.isDark() else \"white\"\n",
    "ink = \"white\" if bg == \"black\" else \"black\"\n",
    "markers = {0: \"o\", 1: \"s\", 2: \"D\", 3: \"^\", 4: \"<\", 5: \">\", 6: \"+\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chex.dataclass\n",
    "class Config:\n",
    "    env_name: str = \"smax\"\n",
    "    scenario: str = \"simple_wood_and_stone\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "n_envs = 6\n",
    "n_steps = 100\n",
    "scenario = \"3s5z_vs_3s6z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter\n",
    "def step_fn(rng, env, obs_v, old_state_v):\n",
    "    rng, act_rng, step_rng = random.split(rng, 3)\n",
    "    act_keys = random.split(act_rng, env.num_agents * n_envs).reshape(\n",
    "        env.num_agents, n_envs, -1\n",
    "    )\n",
    "    step_keys = random.split(step_rng, n_envs)\n",
    "    actions = {\n",
    "        a: action_fn(env, act_keys[i], obs_v[a], a) for i, a in enumerate(env.agents)\n",
    "    }\n",
    "    obs_v, state_v, reward_v, _, _ = vmap(env.step)(step_keys, old_state_v, actions)\n",
    "    return (rng, env, obs_v, state_v), (step_keys, old_state_v, actions), reward_v\n",
    "\n",
    "\n",
    "@partial(vmap, in_axes=(None, 0, 0, None))\n",
    "def action_fn(env, rng, obs, a):\n",
    "    # get observation, ignore it and rake random action.\n",
    "    # next step is to call some bt stuff.\n",
    "    return env.action_space(a).sample(rng)\n",
    "\n",
    "\n",
    "def traj_fn(rng, env):\n",
    "    rng, reset_rng = random.split(random.PRNGKey(0))\n",
    "    reset_keys = random.split(reset_rng, n_envs)\n",
    "    obs_v, state_v = vmap(env.reset)(reset_keys)\n",
    "    traj_state = (rng, env, obs_v, state_v)\n",
    "    state_seq, reward_seq = [], []\n",
    "    for step in tqdm(range(n_steps)):\n",
    "        traj_state, state_v, reward_v = step_fn(*traj_state)\n",
    "        state_seq, reward_seq = state_seq + [state_v], reward_seq + [reward_v]\n",
    "    return state_seq, reward_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 31.16it/s]\n"
     ]
    }
   ],
   "source": [
    "env = make(\"SMAX\", scenario=map_name_to_scenario(scenario))\n",
    "rng, key = random.split(random.PRNGKey(0))\n",
    "state_seq, reward_seq = traj_fn(key, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fn(env, state_seq, reward_seq, expand=False):\n",
    "    \"\"\"\n",
    "    given an environment, a state_seq, and a reward seq\n",
    "    this function makes a small multiples plot of the trejectory.\n",
    "    It save it as a .mp4 film in docs/figs along with an image of the last frame.\n",
    "    \"\"\"\n",
    "    state_seq = (\n",
    "        state_seq if not expand else vmap(env.expand_state_seq)(state_seq)\n",
    "    )  # expand states for smooth animation\n",
    "    frames = []  # frames to make .mp4\n",
    "    unit_types = np.unique(\n",
    "        np.array(state_seq[0][1].unit_types)\n",
    "    )  # unit types for plotting markers\n",
    "    for jdx, (_, state, action) in tqdm(enumerate(state_seq), total=len(state_seq)):\n",
    "        reward = reward_seq[jdx // 8 if expand else jdx]\n",
    "        fills = np.where(np.array(state.unit_teams) == 1, ink, \"None\")  # team colors\n",
    "        fig, axes = plt.subplots(\n",
    "            2, 3, figsize=(17.92, 12.16), facecolor=bg, dpi=100\n",
    "        )  # frame in .mp4 film\n",
    "        for idx, ax in zip(range(n_envs), axes.flatten()):\n",
    "            ax_fn(ax, state, reward, idx)  # setup axis theme\n",
    "            for unit_type in unit_types:\n",
    "                kdx = state.unit_types[idx, :] == unit_type  # unit_type idxs\n",
    "                x = state.unit_positions[idx, kdx, 0]  # x coord\n",
    "                y = state.unit_positions[idx, kdx, 1]  # y coord\n",
    "                c = fills[idx, kdx]  # color\n",
    "                s = state.unit_health[idx, kdx] ** 1.5 * 0.2  # size\n",
    "                ax.scatter(x, y, s=s, c=c, edgecolor=ink, marker=markers[unit_type])\n",
    "        frames.append(frame_fn(fig, jdx // 8 if expand else jdx))\n",
    "    imageio.mimsave(\n",
    "        f'docs/figs/worlds_{bg}{\"_laggy\" if not expand else \"\"}.mp4',\n",
    "        frames,\n",
    "        fps=24 if expand else 3,\n",
    "    )\n",
    "\n",
    "\n",
    "def frame_fn(fig, idx):\n",
    "    title = f\"step : {str(idx).zfill(len(str(n_steps - 1)))}     model : random     env : {scenario}\"\n",
    "    fig.text(0.01, 0.5, title, va=\"center\", rotation=\"vertical\", fontsize=20, color=ink)\n",
    "    plt.subplots_adjust(\n",
    "        left=0.05, bottom=0.05, right=0.95, top=0.95, wspace=0.3, hspace=0.3\n",
    "    )\n",
    "    fig.canvas.draw()\n",
    "    frame = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "    frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (4,))[:, :, :3]\n",
    "    if idx == n_steps - 1:\n",
    "        plt.savefig(f\"docs/figs/worlds_{bg}.jpg\", dpi=200)\n",
    "    plt.close()  # close fig\n",
    "    return frame\n",
    "\n",
    "\n",
    "def ax_fn(\n",
    "    ax, state, reward, idx\n",
    "):  # TODO: add augmentation functions to put dynamic info/metrics around subplots\n",
    "    ally_rewards = sum([v[idx] for k, v in reward.items() if k.startswith(\"ally\")])\n",
    "    enemy_rewards = sum([v[idx] for k, v in reward.items() if k.startswith(\"enemy\")])\n",
    "    ax.set_xlabel(\"{:.3f} | {:.3f}\".format(ally_rewards, enemy_rewards), color=ink)\n",
    "    ax.set_title(f\"simulation {idx+1}\", color=ink)\n",
    "    ax.set_facecolor(bg)\n",
    "    ticks = np.arange(2, 31, 4)  # Assuming your grid goes from 0 to 32\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.tick_params(\n",
    "        colors=ink,\n",
    "        direction=\"in\",\n",
    "        length=6,\n",
    "        width=1,\n",
    "        which=\"both\",\n",
    "        top=True,\n",
    "        bottom=True,\n",
    "        left=True,\n",
    "        right=True,\n",
    "        labelleft=False,\n",
    "        labelbottom=False,\n",
    "    )\n",
    "    ax.spines[\"top\"].set_color(ink)\n",
    "    ax.spines[\"bottom\"].set_color(ink)\n",
    "    ax.spines[\"left\"].set_color(ink)\n",
    "    ax.spines[\"right\"].set_color(ink)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlim(-2, 34)\n",
    "    ax.set_ylim(-2, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [02:05<00:00,  6.37it/s]\n"
     ]
    }
   ],
   "source": [
    "plot_fn(env, state_seq, reward_seq, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bullet proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2107.10it/s]\n"
     ]
    }
   ],
   "source": [
    "def dist_fn(pos):  # computing the distances between all ally and enemy agents\n",
    "    delta = pos[None, :, :] - pos[:, None, :]  # get all the delta vectors\n",
    "    dist = jnp.sqrt((delta**2).sum(axis=2))  # dists between every agent\n",
    "    dist = dist[: env.num_allies, env.num_allies :]  # row is ally, col is enemy\n",
    "    return {\"ally\": dist, \"enemy\": dist.T}  # rember dist is associativ\n",
    "\n",
    "\n",
    "def range_fn(dists, ranges):\n",
    "    ally_range = dists[\"ally\"] < ranges[: env.num_allies][:, None]\n",
    "    enemy_range = dists[\"enemy\"] < ranges[env.num_allies :][:, None]\n",
    "    return {\"ally\": ally_range, \"enemy\": enemy_range}\n",
    "\n",
    "\n",
    "def target_fn(acts, in_range, team):\n",
    "    t_acts = jnp.stack([v for k, v in acts.items() if k.startswith(team)]).T\n",
    "    t_targets = jnp.where(t_acts - 5 < 0, -1, t_acts - 5)  # 5 is the attack range\n",
    "    t_attacks = jnp.eye(in_range[team].shape[2] + 1)[t_targets][:, :, :-1]\n",
    "    return t_attacks\n",
    "\n",
    "\n",
    "def bullet_fn(acts, in_range):\n",
    "    target = partial(target_fn, acts, in_range)\n",
    "    return {\"ally\": target(\"ally\"), \"enemy\": target(\"enemy\")}\n",
    "\n",
    "\n",
    "@jit\n",
    "def attack_fn(state, acts):\n",
    "    dists = vmap(dist_fn)(state.unit_positions)  # compute distances\n",
    "    ranges = env.unit_type_attack_ranges[state.unit_types]  # get attack ranges\n",
    "    in_range = vmap(range_fn)(dists, ranges)  # compute in range\n",
    "    attacks = bullet_fn(acts, in_range)  # compute attacks\n",
    "    return attacks\n",
    "\n",
    "\n",
    "for _, state, acts in tqdm(state_seq):  # TODO: precompute\n",
    "    bullets = attack_fn(state, acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
